<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Information Retrieval]]></title>
  <link href="http://info4300.notes.parkermoore.de/atom.xml" rel="self"/>
  <link href="http://info4300.notes.parkermoore.de/"/>
  <updated>2012-11-01T13:03:47-04:00</updated>
  <id>http://info4300.notes.parkermoore.de/</id>
  <author>
    <name><![CDATA[Parker J. Moore, pjm336[at]cornell.edu]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[DFS &amp; MapReduce]]></title>
    <link href="http://info4300.notes.parkermoore.de/2012/11/01/dfs-mapreduce/"/>
    <updated>2012-11-01T12:08:00-04:00</updated>
    <id>http://info4300.notes.parkermoore.de/2012/11/01/dfs-mapreduce</id>
    <content type="html"><![CDATA[<h3>Hadoop</h3>

<p>Hadoop is an open-source implementation that combines MapReduce and Distributed File-System technologies.</p>

<p>Useful for the indexing side of web searching.</p>

<ul>
<li>Designed for hundreds of thousands of server machines</li>
<li>Add or remove physical machines at any time</li>
<li>Automatic detection of faults (with quick, automatic recover)</li>
<li>Optimized for larger files, not many small files.</li>
<li>Supports write-once-read-many access model first and foremost</li>
<li>Automatic replication (~3 times, usually)</li>
<li>No other backup!</li>
</ul>


<p>Hadoop is used by many large, well-known companies. It is believed that Facebook uses Hadoop.</p>

<h3>GFS &amp; HFS</h3>

<h4>Literature</h4>

<ul>
<li><a href="http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en/us/archive/gfs-sosp2003.pdf">GFS</a></li>
</ul>


<h4>Overview</h4>

<ul>
<li>Built from many inexpensive components that often fail.</li>
<li>Optimized for 100MB+ files</li>
<li>High sustained bandwidth is more important than low latency</li>
</ul>


<h4>Workload</h4>

<ul>
<li>Two kinds of reads are most common:

<ul>
<li>large streamin reads</li>
<li>small random reads</li>
</ul>
</li>
<li>many large, sequential writes that append data to files</li>
<li>once written, files are seldom modified again</li>
</ul>


<h4>Architecture</h4>

<ul>
<li>Cluster

<ul>
<li>contains a single <strong>master</strong> and several <strong>chunkservers</strong></li>
<li>clients and chunkservers can be run on the same computers</li>
</ul>
</li>
<li>Files divided into fixed-sized <strong>chunks</strong>. Each chunk has a unique 64-bit <strong>chunk handle</strong> assigned by master server</li>
<li>Chunkservers store the chunks on local disks as linux files, and read &amp; write</li>
</ul>


<h4>Client interactions</h4>

<ul>
<li>A client asks the master which chunkservers it should contact and completes the file exchange with that chunkserver directly (not via master)</li>
</ul>


<h3>Programming for Large Computer Clusters</h3>

<h4>Goal</h4>

<ul>
<li>Create env in which less-experienced programmers could develop useful network services quickly</li>
<li>Separate app programmers from the complexities of the DFS</li>
</ul>


<h4>Academic researcher programmers</h4>

<ul>
<li>Deep knowledge of domain</li>
<li>Good algorithmic understanding</li>
</ul>


<p>BUT&#8230;</p>

<ul>
<li>Has limited understanding of large-scale data analysis</li>
<li>not skilled in any form of concurrent computing</li>
</ul>


<h4>Tape-Based Computing</h4>

<h5>Problem:</h5>

<ul>
<li>Waaaaay too much data to build data structures in memory</li>
<li>Disk I/O waaaay to slow for random access</li>
</ul>


<h5>Solution</h5>

<ul>
<li>Data managed by short key-value pairs</li>
<li>To process data:

<ul>
<li>split data into key-value pairs</li>
<li>sort data by key</li>
<li>merge files so that all values wht the same key are processed together</li>
<li>proess all the values for a single key</li>
<li>write out 1+ records for each key</li>
</ul>
</li>
</ul>


<h3>MapReduce</h3>

<h4>Programming</h4>

<ul>
<li><strong>Map</strong> takes an input pair and produces a set of intermediate key-value pairs</li>
<li><strong>Combiner</strong> merges all intermediate values associated with the saame intermediate key and passes them to Reduce</li>
<li><strong>Reduce</strong> accepts an intermediate key and a set of values for that key, combines these values to form a possibly smaller set of values</li>
</ul>


<h5>Map</h5>

<ul>
<li>Input: <code>(u0, v0)</code></li>
<li>Output:

<ul>
<li><code>(u, d)</code> &mdash; Dummy <code>d</code> indicates that <code>u</code> is a from-URL</li>
<li><code>(v, u)</code> &mdash; Indicate that <code>v</code> is a to-URL with link from <code>u</code></li>
<li><code>d</code> is a dummy marker.  Do not output if <code>u</code> = <code>v</code>.</li>
</ul>
</li>
<li>The output is a set of keys, which are all the URLs, with values that depend on whether they are from-URLs or to-URLs.</li>
</ul>


<h5>Combiner</h5>

<ul>
<li>The input to the reduce process merges the output values from the map task that correspond to each key (URL).</li>
<li>It combines all the (key, value) pairs from Map that have the same key.  For each URL, <code>w</code>, it creates a list:

<ul>
<li><code>w, {d, ... , d, u1, ..., uk}</code></li>
</ul>
</li>
<li>The Combine operation is performed automatically by the system libraries.</li>
</ul>


<h5>Reduce</h5>

<ul>
<li>Input: <code>(w, {d, ..., d, u1, ..., uk})</code>, where <code>w</code> is any URL.</li>
<li>Output:

<ul>
<li>If d does not exist, discard and do not output (corresponds to a URL that never appears as the first element of a (u, v) pair)</li>
<li>Otherwise, remove duplicates from <code>u1, ..., uk</code> and output.</li>
</ul>
</li>
<li>The output is a to-URL and a list of the nodes that link to it: <code>v, {u1, ..., uk}</code></li>
</ul>


<h4>Cluster Implementation</h4>

<p><img src="http://info4300.notes.parkermoore.de/images/mapreduce-implementation.png" title="&#34;Visual representation of MapReduce&#34;" alt="&#34;Visual representation of MapReduce&#34;"></p>

<h3>Scalability</h3>

<ul>
<li>Web search services are monolithic centralized systems (though use distributed data centers)</li>
<li>Moore&#8217;s Law allows for scalability on a grand scale</li>
<li>Harder to maintain quality of software when more and more people work on the same code base</li>
<li>Solution: MODULAR DEVELOPMENT</li>
<li>Organize for minimal staff in systems management as well as customer service</li>
<li>AUTOMATE AUTOMATE AUTOMATE</li>
</ul>

]]></content>
  </entry>
  
</feed>
